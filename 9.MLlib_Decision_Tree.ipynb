{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size is 4898431\n"
     ]
    }
   ],
   "source": [
    "data_file = \"./kddcup.data.gz\"\n",
    "raw_data = sc.textFile(data_file)\n",
    "\n",
    "print(\"Train data size is {}\".format(raw_data.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data size is 311029\n"
     ]
    }
   ],
   "source": [
    "test_data_file = \"./corrected.gz\"\n",
    "test_raw_data = sc.textFile(test_data_file)\n",
    "\n",
    "print(\"Test data size is {}\".format(test_raw_data.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "import numpy as np\n",
    "\n",
    "csv_data = raw_data.map(lambda x:x.split(','))\n",
    "test_csv_data = test_raw_data.map(lambda x:x.split(','))\n",
    "\n",
    "protocols = csv_data.map(lambda x:x[1]).distinct().collect()\n",
    "services = csv_data.map(lambda x:x[2]).distinct().collect()\n",
    "flags = csv_data.map(lambda x:x[3]).distinct().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can use this Python lists in our create_labeled_point function. If a factor level is not in the training data, we assign an especial level. Remember that we cannot use testing data for training our model, not even the factor levels. The testing data represents the unknown to us in a real case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_labeled_point(line_split):\n",
    "    clean_line_split = line_split[0:41]\n",
    "    try:\n",
    "        clean_line_split[1] = protocols.index(clean_line_split[1])\n",
    "    except:\n",
    "        clean_line_split[1] = len(protocols)\n",
    "        \n",
    "    try:\n",
    "        clean_line_split[2] = services.index(clean_line_split[2])\n",
    "    except:\n",
    "        clean_line_split[2] = len(services)\n",
    "    \n",
    "    # convert flag to numeric categorical variable\n",
    "    try:\n",
    "        clean_line_split[3] = flags.index(clean_line_split[3])\n",
    "    except:\n",
    "        clean_line_split[3] = len(flags)\n",
    "    \n",
    "    # convert label to binary label\n",
    "    attack = 1.0\n",
    "    if line_split[41] == 'normal.':\n",
    "        attack = 0.0\n",
    "    \n",
    "    return LabeledPoint(attack,np.array([float(x) for x in clean_line_split]))\n",
    "\n",
    "training_data = csv_data.map(create_labeled_point)\n",
    "test_data = test_csv_data.map(create_labeled_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier trained in 104.302 seconds\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.tree import DecisionTree,DecisionTreeModel\n",
    "from time import time\n",
    "\n",
    "# Build model\n",
    "t0 = time()\n",
    "tree_model = DecisionTree.trainClassifier(training_data,numClasses=2,\n",
    "                                          categoricalFeaturesInfo={1:len(protocols),\n",
    "                                                                   2:len(services),\n",
    "                                                                   3:len(flags)},\n",
    "                                          impurity='gini',maxDepth=4,maxBins=100)\n",
    "tt = time() - t0\n",
    "print (\"Classifier trained in {} seconds\".format(round(tt,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = tree_model.predict(test_data.map(lambda p:p.features))\n",
    "labels_and_preds = test_data.map(lambda p:p.label).zip(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction made in 8.109 seconds. Test accuracy is 0.915\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "test_accuracy = labels_and_preds.filter(lambda x: x[0] == x[1]).count() / float(test_data.count())\n",
    "tt = time() - t0\n",
    "\n",
    "print(\"Prediction made in {} seconds. Test accuracy is {}\".format(round(tt,3), round(test_accuracy,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned classification tree model:\n",
      "DecisionTreeModel classifier of depth 4 with 23 nodes\n",
      "  If (feature 22 <= 88.5)\n",
      "   If (feature 38 <= 0.7949999999999999)\n",
      "    If (feature 36 <= 0.49)\n",
      "     If (feature 34 <= 0.9550000000000001)\n",
      "      Predict: 0.0\n",
      "     Else (feature 34 > 0.9550000000000001)\n",
      "      Predict: 1.0\n",
      "    Else (feature 36 > 0.49)\n",
      "     If (feature 2 in {0.0,5.0,24.0,25.0,14.0,20.0,29.0,1.0,21.0,13.0,2.0,17.0,22.0,27.0,7.0,3.0,11.0,26.0,23.0,8.0,19.0,4.0})\n",
      "      Predict: 0.0\n",
      "     Else (feature 2 not in {0.0,5.0,24.0,25.0,14.0,20.0,29.0,1.0,21.0,13.0,2.0,17.0,22.0,27.0,7.0,3.0,11.0,26.0,23.0,8.0,19.0,4.0})\n",
      "      Predict: 1.0\n",
      "   Else (feature 38 > 0.7949999999999999)\n",
      "    If (feature 3 in {0.0,1.0,6.0,2.0,8.0})\n",
      "     Predict: 0.0\n",
      "    Else (feature 3 not in {0.0,1.0,6.0,2.0,8.0})\n",
      "     Predict: 1.0\n",
      "  Else (feature 22 > 88.5)\n",
      "   If (feature 5 <= 2.0)\n",
      "    If (feature 11 <= 0.5)\n",
      "     Predict: 1.0\n",
      "    Else (feature 11 > 0.5)\n",
      "     If (feature 2 in {14.0})\n",
      "      Predict: 0.0\n",
      "     Else (feature 2 not in {14.0})\n",
      "      Predict: 1.0\n",
      "   Else (feature 5 > 2.0)\n",
      "    If (feature 29 <= 0.08499999999999999)\n",
      "     If (feature 2 in {0.0,5.0,10.0,1.0,2.0,22.0,8.0})\n",
      "      Predict: 0.0\n",
      "     Else (feature 2 not in {0.0,5.0,10.0,1.0,2.0,22.0,8.0})\n",
      "      Predict: 1.0\n",
      "    Else (feature 29 > 0.08499999999999999)\n",
      "     Predict: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Learned classification tree model:\")\n",
    "print(tree_model.toDebugString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_labeled_point_minimal(line_split):\n",
    "    # leave_out = [41]\n",
    "    clean_line_split = line_split[3:4] + line_split[5:6] + line_split[22:23]\n",
    "    \n",
    "    # convert flag to numeric categorical variable\n",
    "    try:\n",
    "        clean_line_split[0] = flags.index(clean_line_split[0])\n",
    "    except:\n",
    "        clean_line_split[0] = len(flags)\n",
    "    \n",
    "    # convert label to binary label\n",
    "    attack = 1.0\n",
    "    if line_split[41]=='normal.':\n",
    "        attack = 0.0\n",
    "        \n",
    "    return LabeledPoint(attack, np.array([float(x) for x in clean_line_split]))\n",
    "\n",
    "training_data_minimal = csv_data.map(create_labeled_point_minimal)\n",
    "test_data_minimal = test_csv_data.map(create_labeled_point_minimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier trained in 66.613 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "tree_model_minial = DecisionTree.trainClassifier(training_data_minimal,\n",
    "                                                 numClasses=2,categoricalFeaturesInfo={0:len(flags)},\n",
    "                                                 impurity='gini',maxDepth=3,maxBins=32)\n",
    "tt = time() - t0\n",
    "print(\"Classifier trained in {} seconds\".format(round(tt,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_minimal = tree_model_minial.predict(test_data_minimal.map(lambda p: p.features))\n",
    "labels_and_preds_minimal = test_data_minimal.map(lambda p: p.label).zip(predictions_minimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction made in 4.373 seconds. Test accuracy is 0.9055\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "test_accuracy = labels_and_preds_minimal.filter(lambda x: x[0] == x[1]).count() / float(test_data_minimal.count())\n",
    "tt = time() - t0\n",
    "\n",
    "print(\"Prediction made in {} seconds. Test accuracy is {}\".format(round(tt,3), round(test_accuracy,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
