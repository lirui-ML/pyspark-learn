{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will use Spark's machine learning library MLlib to build a Logistic Regression classifier for network attack detection. We will use the complete KDD Cup 1999 datasets in order to test Spark capabilities with large datasets.\n",
    "\n",
    "Additionally, we will introduce two ways of performing model selection: by using a correlation matrix and by using hypothesis testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size is 4898431\n"
     ]
    }
   ],
   "source": [
    "data_file = \"./kddcup.data.gz\"\n",
    "raw_data = sc.textFile(data_file)\n",
    "\n",
    "print(\"Train data size is {}\".format(raw_data.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data size is 311029\n"
     ]
    }
   ],
   "source": [
    "test_data_file = './corrected.gz'\n",
    "test_raw_data = sc.textFile(test_data_file)\n",
    "print(\"Test data size is {}\".format(test_raw_data.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeled Points\n",
    "A labeled point is a local vector associated with a label/response. In MLlib, labeled points are used in supervised learning algorithms and they are stored as doubles. For binary classification, a label should be either 0 (negative) or 1 (positive).\n",
    "\n",
    "### Preparing the training data\n",
    "In our case, we are interested in detecting network attacks in general. We don't need to detect which type of attack we are dealing with. Therefore we will tag each network interaction as non attack (i.e. 'normal' tag) or attack (i.e. anything else but 'normal')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "import numpy as np\n",
    "\n",
    "def parse_interaction(line):\n",
    "    line_split = line.split(',')\n",
    "    clean_line_split = line_split[0:1] + line_split[4:41]\n",
    "    attack = 1.0\n",
    "    if line_split[41] == 'normal.':\n",
    "        attack = 0.0\n",
    "    return LabeledPoint(attack,np.array([float(x) for x in clean_line_split]))\n",
    "\n",
    "training_data = raw_data.map(parse_interaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.take(1)[0].label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = test_raw_data.map(parse_interaction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting network attacks using Logistic Regression\n",
    "Logistic regression is widely used to predict a binary response. Spark implements two algorithms to solve logistic regression: mini-batch gradient descent and L-BFGS. L-BFGS is recommended over mini-batch gradient descent for faster convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier trained in 1192.259 seconds\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# build the model\n",
    "T0 = timer()\n",
    "mlr = LogisticRegressionWithLBFGS.train(training_data)\n",
    "T1 = timer() - T0\n",
    "\n",
    "print('Classifier trained in {} seconds'.format(round(T1,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3925650"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.filter(lambda x:x.label == 1.0).count()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "972781"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.filter(lambda x:x.label == 0.0).count()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.035492058335843"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3925650/972781"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model on new data\n",
    "In order to measure the classification error on our test data, we use map on the test_data RDD and the model to predict each test point class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_and_preds = test_data.map(lambda p:(p.label,mlr.predict(p.features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 0)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_and_preds.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction made in 8.274472 seconds. Test accuracy is 0.8626\n"
     ]
    }
   ],
   "source": [
    "t0 = timer()\n",
    "test_accuracy = labels_and_preds.filter(lambda x:x[0] == x[1]).count() / float(test_data.count())\n",
    "tt = timer() - t0\n",
    "\n",
    "print(\"Prediction made in {:3f} seconds. Test accuracy is {:.4f}\".format(tt,test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selection\n",
    "\n",
    "#### Using a correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_interaction_corr(line):\n",
    "    line_split = line.split(\",\")\n",
    "    # leave_out = [1,2,3,25,27,35,38,40,41]\n",
    "    clean_line_split = line_split[0:1]+line_split[4:25]+line_split[26:27]+line_split[28:35]+line_split[36:38]+line_split[39:40]\n",
    "    attack = 1.0\n",
    "    if line_split[41]=='normal.':\n",
    "        attack = 0.0\n",
    "    return LabeledPoint(attack, np.array([float(x) for x in clean_line_split]))\n",
    "\n",
    "corr_reduced_training_data = raw_data.map(parse_interaction_corr)\n",
    "corr_reduced_test_data = test_raw_data.map(parse_interaction_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier trained in 1180.0 seconds\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "t0 = timer()\n",
    "logit_model_2 = LogisticRegressionWithLBFGS.train(corr_reduced_training_data)\n",
    "tt = timer() - t0\n",
    "\n",
    "print(\"Classifier trained in {} seconds\".format(round(tt,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction made in 8.137 seconds. Test accuracy is 0.8134\n"
     ]
    }
   ],
   "source": [
    "labels_and_preds = corr_reduced_test_data.map(lambda p: (p.label, logit_model_2.predict(p.features)))\n",
    "t0 = timer()\n",
    "test_accuracy = labels_and_preds.filter(lambda x: x[0] == x[1]).count() / float(corr_reduced_test_data.count())\n",
    "tt = timer() - t0\n",
    "\n",
    "print(\"Prediction made in {} seconds. Test accuracy is {}\".format(round(tt,3), round(test_accuracy,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using hypothsis testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_names = [\"land\",\"wrong_fragment\",\n",
    "             \"urgent\",\"hot\",\"num_failed_logins\",\"logged_in\",\"num_compromised\",\n",
    "             \"root_shell\",\"su_attempted\",\"num_root\",\"num_file_creations\",\n",
    "             \"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\n",
    "             \"is_hot_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\n",
    "             \"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\n",
    "             \"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\n",
    "             \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n",
    "             \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n",
    "             \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_interaction_categorical(line):\n",
    "    line_split = line.split(\",\")\n",
    "    clean_line_split = line_split[6:41]\n",
    "    attack = 1.0\n",
    "    if line_split[41]=='normal.':\n",
    "        attack = 0.0\n",
    "    return LabeledPoint(attack, np.array([float(x) for x in clean_line_split]))\n",
    "\n",
    "training_data_categorical = raw_data.map(parse_interaction_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.stat import Statistics\n",
    "\n",
    "chi = Statistics.chiSqTest(training_data_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Statistic</th>\n",
       "      <th>p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>land</th>\n",
       "      <td>4.649835e-01</td>\n",
       "      <td>4.953041e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wrong_fragment</th>\n",
       "      <td>3.068555e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>urgent</th>\n",
       "      <td>3.871844e+01</td>\n",
       "      <td>2.705761e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hot</th>\n",
       "      <td>1.946331e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_failed_logins</th>\n",
       "      <td>1.277691e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logged_in</th>\n",
       "      <td>3.273098e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_compromised</th>\n",
       "      <td>2.011863e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>root_shell</th>\n",
       "      <td>1.044918e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>su_attempted</th>\n",
       "      <td>4.340000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_root</th>\n",
       "      <td>2.287168e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_file_creations</th>\n",
       "      <td>9.179739e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_shells</th>\n",
       "      <td>1.380028e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_access_files</th>\n",
       "      <td>1.873477e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_outbound_cmds</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_hot_login</th>\n",
       "      <td>8.070987e+00</td>\n",
       "      <td>4.497960e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_guest_login</th>\n",
       "      <td>1.350051e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.546398e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>srv_count</th>\n",
       "      <td>2.296060e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>serror_rate</th>\n",
       "      <td>2.684199e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>srv_serror_rate</th>\n",
       "      <td>3.026270e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rerror_rate</th>\n",
       "      <td>9.860453e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>srv_rerror_rate</th>\n",
       "      <td>3.247639e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>same_srv_rate</th>\n",
       "      <td>3.999124e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff_srv_rate</th>\n",
       "      <td>3.909998e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>srv_diff_host_rate</th>\n",
       "      <td>1.365459e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dst_host_count</th>\n",
       "      <td>2.520479e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <td>1.439086e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <td>1.237932e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <td>1.339002e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <td>2.915195e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <td>2.226291e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <td>4.074546e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <td>4.550990e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <td>1.364790e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <td>2.545474e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Statistic       p-value\n",
       "land                         4.649835e-01  4.953041e-01\n",
       "wrong_fragment               3.068555e+02  0.000000e+00\n",
       "urgent                       3.871844e+01  2.705761e-07\n",
       "hot                          1.946331e+04  0.000000e+00\n",
       "num_failed_logins            1.277691e+02  0.000000e+00\n",
       "logged_in                    3.273098e+06  0.000000e+00\n",
       "num_compromised              2.011863e+03  0.000000e+00\n",
       "root_shell                   1.044918e+03  0.000000e+00\n",
       "su_attempted                 4.340000e+02  0.000000e+00\n",
       "num_root                     2.287168e+04  0.000000e+00\n",
       "num_file_creations           9.179739e+03  0.000000e+00\n",
       "num_shells                   1.380028e+03  0.000000e+00\n",
       "num_access_files             1.873477e+04  0.000000e+00\n",
       "num_outbound_cmds            0.000000e+00  1.000000e+00\n",
       "is_hot_login                 8.070987e+00  4.497960e-03\n",
       "is_guest_login               1.350051e+04  0.000000e+00\n",
       "count                        4.546398e+06  0.000000e+00\n",
       "srv_count                    2.296060e+06  0.000000e+00\n",
       "serror_rate                  2.684199e+05  0.000000e+00\n",
       "srv_serror_rate              3.026270e+05  0.000000e+00\n",
       "rerror_rate                  9.860453e+03  0.000000e+00\n",
       "srv_rerror_rate              3.247639e+04  0.000000e+00\n",
       "same_srv_rate                3.999124e+05  0.000000e+00\n",
       "diff_srv_rate                3.909998e+05  0.000000e+00\n",
       "srv_diff_host_rate           1.365459e+06  0.000000e+00\n",
       "dst_host_count               2.520479e+06  0.000000e+00\n",
       "dst_host_srv_count           1.439086e+06  0.000000e+00\n",
       "dst_host_same_srv_rate       1.237932e+06  0.000000e+00\n",
       "dst_host_diff_srv_rate       1.339002e+06  0.000000e+00\n",
       "dst_host_same_src_port_rate  2.915195e+06  0.000000e+00\n",
       "dst_host_srv_diff_host_rate  2.226291e+06  0.000000e+00\n",
       "dst_host_serror_rate         4.074546e+05  0.000000e+00\n",
       "dst_host_srv_serror_rate     4.550990e+05  0.000000e+00\n",
       "dst_host_rerror_rate         1.364790e+05  0.000000e+00\n",
       "dst_host_srv_rerror_rate     2.545474e+05  0.000000e+00"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 30)\n",
    "\n",
    "records = [(result.statistic, result.pValue) for result in chi]\n",
    "\n",
    "chi_df = pd.DataFrame(data=records, index= feature_names, columns=[\"Statistic\",\"p-value\"])\n",
    "\n",
    "chi_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From that we conclude that predictors land and num_outbound_cmds could be removed from our model without affecting our accuracy dramatically. Let's try this.\n",
    "\n",
    "#### Evaluating the new model\n",
    "So the only modification to our first parse_interaction function will be to remove columns 6 and 19, corresponding to the two predictors that we want not to be part of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_interaction_chi(line):\n",
    "    line_split = line.split(\",\")\n",
    "    # leave_out = [1,2,3,6,19,41]\n",
    "    clean_line_split = line_split[0:1] + line_split[4:6] + line_split[7:19] + line_split[20:41]\n",
    "    attack = 1.0\n",
    "    if line_split[41]=='normal.':\n",
    "        attack = 0.0\n",
    "    return LabeledPoint(attack, np.array([float(x) for x in clean_line_split]))\n",
    "\n",
    "training_data_chi = raw_data.map(parse_interaction_chi)\n",
    "test_data_chi = test_raw_data.map(parse_interaction_chi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier trained in 1189.98 seconds\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "t0 = timer()\n",
    "logit_model_chi = LogisticRegressionWithLBFGS.train(training_data_chi)\n",
    "tt = timer() - t0\n",
    "\n",
    "print(\"Classifier trained in {} seconds\".format(round(tt,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction made in 8.284 seconds. Test accuracy is 0.872\n"
     ]
    }
   ],
   "source": [
    "labels_and_preds = test_data_chi.map(lambda p: (p.label, logit_model_chi.predict(p.features)))\n",
    "t0 = timer()\n",
    "test_accuracy = labels_and_preds.filter(lambda x: x[0] == x[1]).count() / float(test_data_chi.count())\n",
    "tt = timer() - t0\n",
    "\n",
    "print(\"Prediction made in {} seconds. Test accuracy is {}\".format(round(tt,3), round(test_accuracy,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
